{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\michael\\dev\\streusle-tagger\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"calibration/labels_dict.csv\")\n",
    "label_strings = list(labels_df[\"Label\"])\n",
    "indexes = list(labels_df[\"Index\"])\n",
    "\n",
    "class Label():\n",
    "    \"\"\"A label consists of a bio tag, a lexical category tag, and a supersense (for nouns, verbs, and prepositions (STREUSLE only)\"\"\"\n",
    "    def __init__(self, label_string, index):\n",
    "        self.original = label_string\n",
    "        self.new = \"\"\n",
    "        self.index = index\n",
    "        \n",
    "        # We want to split subtags using \"-\" later, so temporarily replace \"Co-\" (as in \"Co-agent\" or \"Co-theme\" with \"รง\").\n",
    "        label_string = label_string.replace(\"Co-\", \"รง\")\n",
    "        \n",
    "        if label_string.startswith(\"I\"):\n",
    "            self.bio = \"I\"\n",
    "            self.lex = \"_\"\n",
    "            self.sup = \"\"\n",
    "            return\n",
    "        elif label_string.startswith(\"i\"):\n",
    "            self.bio = \"i\"\n",
    "            self.lex = \"_\"\n",
    "            self.sup = \"\"\n",
    "            return\n",
    "        \n",
    "        self.bio = label_string[0]\n",
    "        label_string = label_string[2:]\n",
    "\n",
    "        if \"-\" in label_string:\n",
    "            self.lex, self.sup = label_string.split(\"-\")\n",
    "        else:\n",
    "            self.lex = label_string\n",
    "            self.sup = \"\"\n",
    "            \n",
    "        self.sup = self.sup.lower()\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{self.index}\\t{self.original}\\t{self.new}\\t{self.bio}\\t{self.lex}\\t{self.sup}\"\n",
    "\n",
    "labels = []\n",
    "for l, i in zip(label_strings, indexes):\n",
    "    labels.append(Label(l, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\"CCONJ\": \"CONJ\",\n",
    "              \"DISC\": \"X\",\n",
    "              \"INF\": \"PART\",\n",
    "              \"INF.P\" : \"PART\",\n",
    "              \"N\": \"NOUN\",\n",
    "              \"P\": \"ADP\",\n",
    "              \"POSS\": \"PART\",\n",
    "              \"PP\": \"ADP\",\n",
    "              \"PRON.POSS\": \"PRON\",\n",
    "              \"V\":\n",
    "              \"VERB\",\n",
    "              \"V.IAV\":\"VERB\",\n",
    "              \"V.LVC.cause\": \"VERB\",\n",
    "              \"V.LVC.full\": \"VERB\",\n",
    "              \"V.VID\": \"VERB\",\n",
    "              \"V.VPC.full\": \"VERB\",\n",
    "              \"V.VPC.semi\": \"VERB\",\n",
    "              \"_\": \"X\"}\n",
    "\n",
    "# In first pass, change lexical categories to match DiMSUM labelset\n",
    "for l in labels:\n",
    "    if l.lex in labels_map.keys():\n",
    "        l.lex = labels_map[l.lex]\n",
    "        \n",
    "# In second pass, remove preposition supersenses\n",
    "for l in labels:\n",
    "    if l.sup .startswith(\"p\"):\n",
    "        l.sup = \"\"\n",
    "        \n",
    "# In third pass, set l.new\n",
    "for l in labels:\n",
    "    if l.sup != \"\":\n",
    "        l.new = f\"{l.bio}-{l.lex}-{l.sup}\"\n",
    "    else:\n",
    "        l.new = f\"{l.bio}-{l.lex}\"\n",
    "\n",
    "# In fourth and final pass, create map from each new label to list of indexes from old tagset (e.g. new_labels[\"O-PRON\"] = [1, 28, 34, 54, 70, 78, 80, 100, 142, 242, 251, 288, 309, 348, 371])\n",
    "new_labels = {}\n",
    "for i, l in enumerate(labels):\n",
    "    if l.new not in new_labels:\n",
    "        new_labels[l.new] = [l.index]\n",
    "    else:\n",
    "        new_labels[l.new].append(l.index)\n",
    "\n",
    "with open(\"calibration/consolidated_labels.pickle\", \"wb\") as f:\n",
    "    pickle.dump(new_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Lexcat subtag from consolidated labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"calibration/consolidated_labels.pickle\", \"rb\") as f:\n",
    "    new_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_lexcat_labels = {}\n",
    "for k, v in new_labels.items():\n",
    "    if k.count(\"-\") == 1:\n",
    "        # Keys without supersenses only include the MWE subtag\n",
    "        new_key = k[0]\n",
    "    else:\n",
    "        # Keys with supersenses contain the MWE subtag and the supersense\n",
    "        new_key = k[0] + \"-\" + k[k.index(\"-\", 2) + 1:]\n",
    "        \n",
    "    if new_key not in no_lexcat_labels.keys():\n",
    "        no_lexcat_labels[new_key] = new_labels[k]\n",
    "    else:\n",
    "        no_lexcat_labels[new_key] = no_lexcat_labels[new_key] + new_labels[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"calibration/consolidated_labels_no_lexcat.pickle\", \"wb\") as f:\n",
    "    pickle.dump(no_lexcat_labels, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen",
   "language": "python",
   "name": "allen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
