{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DiMSUM Confidence Scores\n",
    "\n",
    "- Modified dimsum_to_jsonl.py to include label field by composing subtag fields into one string\n",
    "- Read dimsum using dataset_reader\n",
    "- Convert all.csv to all_newlabels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\michael\\dev\\streusle-tagger\n"
     ]
    }
   ],
   "source": [
    "# Notebook starts in notebooks folder. Change working directory back to streusle-tagger\n",
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\michael\\apps\\miniconda\\envs\\allen\\lib\\site-packages\\allennlp\\service\\predictors\\__init__.py:23: FutureWarning: allennlp.service.predictors.* has been depreciated. Please use allennlp.predictors.*\n",
      "  \"Please use allennlp.predictors.*\", FutureWarning)\n",
      "C:\\michael\\apps\\miniconda\\envs\\allen\\lib\\site-packages\\allennlp\\service\\predictors\\predictor.py:6: FutureWarning: allennlp.service.predictors.* has been deprecated. Please use allennlp.predictors.*\n",
      "  \" Please use allennlp.predictors.*\", FutureWarning)\n",
      "_jsonnet not loaded, treating training_config/streusle_bert_large_cased/streusle_bert_large_cased_no_constraints.jsonnet as json\n",
      "Your BERT model appears to be cased, but your indexer is lowercasing tokens.\n",
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
      "2723it [00:00, 5945.43it/s]\n",
      "554it [00:00, 5276.33it/s]\n",
      "535it [00:00, 10700.93it/s]\n",
      "Your BERT model appears to be cased, but your indexer is lowercasing tokens.\n",
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n"
     ]
    }
   ],
   "source": [
    "# System imports\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# Add parent of streusle-tagger to path (streusle should be in this folder)\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "# External imports\n",
    "import allennlp.nn.util as util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.util import import_submodules\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.training.util import datasets_from_params\n",
    "\n",
    "import_submodules(\"streusle_tagger\")\n",
    "\n",
    "params = Params.from_file(\"training_config/streusle_bert_large_cased/streusle_bert_large_cased_no_constraints.jsonnet\")\n",
    "datasets = datasets_from_params(deepcopy(params))\n",
    "dataset_reader_params = deepcopy(params).pop(\"dataset_reader\")\n",
    "dataset_reader = DatasetReader.from_params(dataset_reader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "with open(\"calibration/consolidated_labels_no_lexcat.pickle\", \"rb\") as f:\n",
    "    new_labels = pickle.load(f)\n",
    "\n",
    "dimsum_consolidated_path = \"calibration/confidence_scores/dimsum_test/all_consolidated_no_lexcat.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(\"calibration/labels_dict.csv\")\n",
    "\n",
    "dimsum_test_path = \"data/dimsum16/dimsum16_test_updated_labeled_reformatted.json\"\n",
    "\n",
    "def read(file_path):\n",
    "    with open(file_path, 'r') as tagging_file:\n",
    "        tagging_data = json.load(tagging_file)\n",
    "        for i, x in enumerate(tagging_data):\n",
    "            if i % 200 == 0:\n",
    "                print(i)\n",
    "            tokens = [_ for _ in x[\"tokens\"]]\n",
    "            # Get their associated upos\n",
    "            upos_tags = [_ for _ in x[\"upos_tags\"]]\n",
    "\n",
    "            # Get their associated lemma\n",
    "            lemmas = [_ for _ in x[\"lemmas\"]]\n",
    "            \n",
    "            labels = [_ for _ in x[\"label\"]]\n",
    "            \n",
    "            yield dataset_reader.text_to_instance(tokens, upos_tags, lemmas, labels)\n",
    "            \n",
    "dimsum_test = list(read(dimsum_test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground = []\n",
    "for i in dimsum_test:\n",
    "    ground.extend(i.get(\"tags\").labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ground = []\n",
    "\n",
    "# If there's a noun or verb supersense label, the lexcat has to be NOUN or VERB (exceptions are usually due to MWEs)\n",
    "for g in ground:\n",
    "    if \"-n.\" in g and \"NOUN\" not in g:\n",
    "        x = g[:g.index(\"-\", 1) + 1] + \"NOUN\" + g[g.index(\"-\", 2):]\n",
    "    elif \"-v.\" in g and \"VERB\" not in g:\n",
    "        x = g[:g.index(\"-\", 1) + 1] + \"VERB\" + g[g.index(\"-\", 2):]\n",
    "    else:\n",
    "        x = g\n",
    "    corrected_ground.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the CSVs for all sentences and save the merged version\n",
    "confidence_scores_path = \"calibration/confidence_scores/dimsum_test\"\n",
    "\n",
    "dfs = []\n",
    "for filename in os.listdir(confidence_scores_path):\n",
    "    if filename.startswith(\"0\") and filename.endswith(\".csv\"):\n",
    "        df = pd.read_csv(f\"{confidence_scores_path}/{filename}\")\n",
    "        dfs.append(df)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df.to_csv(f\"{confidence_scores_path}/all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Predicted Tags</th>\n",
       "      <th>Predicted Tag Indexes</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>590</th>\n",
       "      <th>591</th>\n",
       "      <th>592</th>\n",
       "      <th>593</th>\n",
       "      <th>594</th>\n",
       "      <th>595</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@JoJoLyrics</td>\n",
       "      <td>O-N-n.COMMUNICATION</td>\n",
       "      <td>27</td>\n",
       "      <td>3.308357e-03</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.187076</td>\n",
       "      <td>2.004502e-02</td>\n",
       "      <td>6.822077e-04</td>\n",
       "      <td>0.022586</td>\n",
       "      <td>...</td>\n",
       "      <td>8.651178e-08</td>\n",
       "      <td>1.191500e-08</td>\n",
       "      <td>1.492807e-07</td>\n",
       "      <td>9.625937e-08</td>\n",
       "      <td>1.617215e-07</td>\n",
       "      <td>2.149607e-08</td>\n",
       "      <td>1.509233e-08</td>\n",
       "      <td>3.212832e-07</td>\n",
       "      <td>1.995928e-07</td>\n",
       "      <td>2.425950e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>O-PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>3.710947e-07</td>\n",
       "      <td>0.995478</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>8.467397e-07</td>\n",
       "      <td>3.974892e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.063442e-10</td>\n",
       "      <td>1.543950e-10</td>\n",
       "      <td>1.109404e-10</td>\n",
       "      <td>1.433815e-10</td>\n",
       "      <td>6.351943e-11</td>\n",
       "      <td>1.549071e-10</td>\n",
       "      <td>1.347726e-10</td>\n",
       "      <td>7.412362e-11</td>\n",
       "      <td>1.141272e-10</td>\n",
       "      <td>4.027880e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hear</td>\n",
       "      <td>O-V-v.perception</td>\n",
       "      <td>45</td>\n",
       "      <td>1.834077e-06</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>3.886628e-04</td>\n",
       "      <td>7.104369e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>6.379876e-09</td>\n",
       "      <td>5.383308e-09</td>\n",
       "      <td>7.684921e-09</td>\n",
       "      <td>3.885210e-09</td>\n",
       "      <td>1.200826e-08</td>\n",
       "      <td>8.716266e-09</td>\n",
       "      <td>7.930803e-09</td>\n",
       "      <td>8.395023e-09</td>\n",
       "      <td>6.668426e-09</td>\n",
       "      <td>1.063727e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>enough</td>\n",
       "      <td>O-ADV</td>\n",
       "      <td>5</td>\n",
       "      <td>1.044289e-05</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>9.836438e-02</td>\n",
       "      <td>1.795487e-03</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>...</td>\n",
       "      <td>2.715171e-09</td>\n",
       "      <td>4.363862e-09</td>\n",
       "      <td>3.653439e-09</td>\n",
       "      <td>2.914954e-09</td>\n",
       "      <td>8.935501e-09</td>\n",
       "      <td>4.649278e-09</td>\n",
       "      <td>4.485106e-09</td>\n",
       "      <td>3.533208e-09</td>\n",
       "      <td>6.058807e-09</td>\n",
       "      <td>3.257677e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>talking</td>\n",
       "      <td>O-V-v.communication</td>\n",
       "      <td>13</td>\n",
       "      <td>3.740599e-05</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>1.134977e-03</td>\n",
       "      <td>9.664433e-06</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>...</td>\n",
       "      <td>2.200114e-08</td>\n",
       "      <td>4.902813e-08</td>\n",
       "      <td>2.117961e-08</td>\n",
       "      <td>2.007143e-08</td>\n",
       "      <td>3.957958e-08</td>\n",
       "      <td>3.524527e-08</td>\n",
       "      <td>3.407447e-08</td>\n",
       "      <td>3.588781e-08</td>\n",
       "      <td>3.603157e-08</td>\n",
       "      <td>5.895182e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Tokens       Predicted Tags  Predicted Tag Indexes  \\\n",
       "0           0  @JoJoLyrics  O-N-n.COMMUNICATION                     27   \n",
       "1           1            I               O-PRON                      1   \n",
       "2           2         hear     O-V-v.perception                     45   \n",
       "3           3       enough                O-ADV                      5   \n",
       "4           4      talking  O-V-v.communication                     13   \n",
       "\n",
       "              0         1         2             3             4         5  \\\n",
       "0  3.308357e-03  0.000672  0.187076  2.004502e-02  6.822077e-04  0.022586   \n",
       "1  3.710947e-07  0.995478  0.000021  8.467397e-07  3.974892e-07  0.000002   \n",
       "2  1.834077e-06  0.000019  0.007406  3.886628e-04  7.104369e-05  0.000004   \n",
       "3  1.044289e-05  0.000255  0.011356  9.836438e-02  1.795487e-03  0.849829   \n",
       "4  3.740599e-05  0.000319  0.013987  1.134977e-03  9.664433e-06  0.003871   \n",
       "\n",
       "   ...           586           587           588           589           590  \\\n",
       "0  ...  8.651178e-08  1.191500e-08  1.492807e-07  9.625937e-08  1.617215e-07   \n",
       "1  ...  1.063442e-10  1.543950e-10  1.109404e-10  1.433815e-10  6.351943e-11   \n",
       "2  ...  6.379876e-09  5.383308e-09  7.684921e-09  3.885210e-09  1.200826e-08   \n",
       "3  ...  2.715171e-09  4.363862e-09  3.653439e-09  2.914954e-09  8.935501e-09   \n",
       "4  ...  2.200114e-08  4.902813e-08  2.117961e-08  2.007143e-08  3.957958e-08   \n",
       "\n",
       "            591           592           593           594           595  \n",
       "0  2.149607e-08  1.509233e-08  3.212832e-07  1.995928e-07  2.425950e-07  \n",
       "1  1.549071e-10  1.347726e-10  7.412362e-11  1.141272e-10  4.027880e-11  \n",
       "2  8.716266e-09  7.930803e-09  8.395023e-09  6.668426e-09  1.063727e-08  \n",
       "3  4.649278e-09  4.485106e-09  3.533208e-09  6.058807e-09  3.257677e-09  \n",
       "4  3.524527e-08  3.407447e-08  3.588781e-08  3.603157e-08  5.895182e-08  \n",
       "\n",
       "[5 rows x 600 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimsum_df = pd.read_csv(f\"{confidence_scores_path}/all.csv\")\n",
    "dimsum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently running confidence scores, so only use corrected ground up to what has been calculated so far.\n",
    "dimsum_df[\"Ground\"] = corrected_ground[0:len(dimsum_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_columns = [\"Token Index\", \"Tokens\", \"Predicted Tag\", \"Predicted Index\", \"Ground\", \"Ground Index\"] + list(new_labels.keys())\n",
    "new_df_columns\n",
    "new_df = pd.DataFrame(columns=new_df_columns)\n",
    "\n",
    "new_df[\"Token Index\"] = dimsum_df[\"Unnamed: 0\"]\n",
    "new_df[\"Tokens\"] = dimsum_df[\"Tokens\"]\n",
    "\n",
    "old_index_to_new_label = {}\n",
    "for k, v in new_labels.items():\n",
    "    for num in v:\n",
    "        old_index_to_new_label[num] = k\n",
    "\n",
    "new_labels_list = list(new_labels)\n",
    "new_label_to_new_index = dict(zip(new_labels_list, list(range(len(new_labels_list)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels and indexes using consolidated labelset\n",
    "predicted_labels = []\n",
    "predicted_label_indexes = []\n",
    "for index in dimsum_df[\"Predicted Tag Indexes\"]:\n",
    "    new_label = old_index_to_new_label[index]\n",
    "    predicted_labels.append(new_label)\n",
    "    new_index = new_label_to_new_index[new_label]\n",
    "    predicted_label_indexes.append(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\"CCONJ\": \"CONJ\",\n",
    "              \"DISC\": \"X\",\n",
    "              \"INF\": \"PART\",\n",
    "              \"INF.P\" : \"PART\",\n",
    "              \"N\": \"NOUN\",\n",
    "              \"P\": \"ADP\",\n",
    "              \"POSS\": \"PART\",\n",
    "              \"PP\": \"ADP\",\n",
    "              \"PRON.POSS\": \"PRON\",\n",
    "              \"V\":\n",
    "              \"VERB\",\n",
    "              \"V.IAV\":\"VERB\",\n",
    "              \"V.LVC.cause\": \"VERB\",\n",
    "              \"V.LVC.full\": \"VERB\",\n",
    "              \"V.VID\": \"VERB\",\n",
    "              \"V.VPC.full\": \"VERB\",\n",
    "              \"V.VPC.semi\": \"VERB\",\n",
    "              \"_\": \"X\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_labels_consolidated = []\n",
    "for i, label in enumerate(dimsum_df[\"Ground\"]):\n",
    "    \n",
    "    label = label.replace(\"natural_object\", \"naturalobject\")\n",
    "    label = label.replace(\"PROPN\", \"NOUN\")\n",
    "    \n",
    "    # For dealing with manually annotated cases where \"lexcat=\" note is provided\n",
    "    if \"lexcat=\" in label:\n",
    "        new_lexcat = label[label.index(\"=\") + 1:]\n",
    "        mapped_new_lexcat = labels_map[new_lexcat] if new_lexcat in labels_map else new_lexcat\n",
    "        new_label = label[:label.index(\"-\") + 1] + mapped_new_lexcat\n",
    "        ground_labels_consolidated.append(new_label)\n",
    "        continue\n",
    "    try:\n",
    "        if label.startswith(\"I\"):\n",
    "            ground_labels_consolidated.append(\"I-X\")\n",
    "        elif label.startswith(\"i\"):\n",
    "            ground_labels_consolidated.append(\"i-X\")\n",
    "        else:\n",
    "            ground_labels_consolidated.append(label)\n",
    "    except:\n",
    "        print(i, \"\\t\", label)\n",
    "        ground_labels_consolidated.append(\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_indexes = []\n",
    "ground_labels_no_lexcat = []\n",
    "for label in ground_labels_consolidated:\n",
    "    try:\n",
    "        if label == \"-1\":\n",
    "            ground_indexes.append(\"-1\")\n",
    "        elif label.count(\"-\") == 2:\n",
    "            no_lexcat_label = label[0] + \"-\" + label[label.index(\"-\", 2) + 1:]\n",
    "        else:\n",
    "            no_lexcat_label = label[0]\n",
    "        ground_labels_no_lexcat.append(no_lexcat_label)\n",
    "        ground_indexes.append(new_label_to_new_index[no_lexcat_label])\n",
    "    except:\n",
    "        ground_indexes.append(\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ground_indexes) == len(ground_labels_no_lexcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"Predicted Tag\"] = predicted_labels\n",
    "new_df[\"Predicted Index\"] = predicted_label_indexes\n",
    "new_df[\"Ground\"] = ground_labels_no_lexcat\n",
    "new_df[\"Ground Index\"] = ground_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token Index</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Predicted Tag</th>\n",
       "      <th>Predicted Index</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Ground Index</th>\n",
       "      <th>O</th>\n",
       "      <th>I</th>\n",
       "      <th>O-v.stative</th>\n",
       "      <th>O-n.group</th>\n",
       "      <th>...</th>\n",
       "      <th>B-??</th>\n",
       "      <th>B-n.plant</th>\n",
       "      <th>o-v.communication</th>\n",
       "      <th>o-v.emotion</th>\n",
       "      <th>b-n.substance</th>\n",
       "      <th>B-n.other</th>\n",
       "      <th>b-v.possession</th>\n",
       "      <th>b-n.quantity</th>\n",
       "      <th>o-n.naturalobject</th>\n",
       "      <th>b-n.location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@JoJoLyrics</td>\n",
       "      <td>O-n.communication</td>\n",
       "      <td>17</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hear</td>\n",
       "      <td>O-v.perception</td>\n",
       "      <td>26</td>\n",
       "      <td>O-v.perception</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>enough</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>talking</td>\n",
       "      <td>O-v.communication</td>\n",
       "      <td>7</td>\n",
       "      <td>O-v.communication</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token Index       Tokens      Predicted Tag  Predicted Index  \\\n",
       "0            0  @JoJoLyrics  O-n.communication               17   \n",
       "1            1            I                  O                0   \n",
       "2            2         hear     O-v.perception               26   \n",
       "3            3       enough                  O                0   \n",
       "4            4      talking  O-v.communication                7   \n",
       "\n",
       "              Ground Ground Index    O    I O-v.stative O-n.group  ... B-??  \\\n",
       "0                  O            0  NaN  NaN         NaN       NaN  ...  NaN   \n",
       "1                  O            0  NaN  NaN         NaN       NaN  ...  NaN   \n",
       "2     O-v.perception           26  NaN  NaN         NaN       NaN  ...  NaN   \n",
       "3                  O            0  NaN  NaN         NaN       NaN  ...  NaN   \n",
       "4  O-v.communication            7  NaN  NaN         NaN       NaN  ...  NaN   \n",
       "\n",
       "  B-n.plant o-v.communication o-v.emotion b-n.substance B-n.other  \\\n",
       "0       NaN               NaN         NaN           NaN       NaN   \n",
       "1       NaN               NaN         NaN           NaN       NaN   \n",
       "2       NaN               NaN         NaN           NaN       NaN   \n",
       "3       NaN               NaN         NaN           NaN       NaN   \n",
       "4       NaN               NaN         NaN           NaN       NaN   \n",
       "\n",
       "  b-v.possession b-n.quantity o-n.naturalobject b-n.location  \n",
       "0            NaN          NaN               NaN          NaN  \n",
       "1            NaN          NaN               NaN          NaN  \n",
       "2            NaN          NaN               NaN          NaN  \n",
       "3            NaN          NaN               NaN          NaN  \n",
       "4            NaN          NaN               NaN          NaN  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_scores(new_label, row_index):\n",
    "    score_sum = 0\n",
    "    \n",
    "    for i in new_labels[new_label]:\n",
    "        score_sum += dimsum_df[str(i)][row_index]\n",
    "        \n",
    "    return score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_column_names = list(new_df.columns)[6:]\n",
    "\n",
    "score_columns = {}\n",
    "for c in score_column_names:\n",
    "    score_columns[c] = []\n",
    "for i, row in new_df.iterrows():\n",
    "    for c in score_column_names:\n",
    "        score_columns[c].append(sum_scores(c, i))\n",
    "\n",
    "for c in score_column_names:\n",
    "    new_df[c] = score_columns[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token Index</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Predicted Tag</th>\n",
       "      <th>Predicted Index</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Ground Index</th>\n",
       "      <th>O</th>\n",
       "      <th>I</th>\n",
       "      <th>O-v.stative</th>\n",
       "      <th>O-n.group</th>\n",
       "      <th>...</th>\n",
       "      <th>B-??</th>\n",
       "      <th>B-n.plant</th>\n",
       "      <th>o-v.communication</th>\n",
       "      <th>o-v.emotion</th>\n",
       "      <th>b-n.substance</th>\n",
       "      <th>B-n.other</th>\n",
       "      <th>b-v.possession</th>\n",
       "      <th>b-n.quantity</th>\n",
       "      <th>o-n.naturalobject</th>\n",
       "      <th>b-n.location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@JoJoLyrics</td>\n",
       "      <td>O-n.communication</td>\n",
       "      <td>17</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311954</td>\n",
       "      <td>0.188062</td>\n",
       "      <td>0.087458</td>\n",
       "      <td>0.021254</td>\n",
       "      <td>...</td>\n",
       "      <td>2.375879e-08</td>\n",
       "      <td>3.950812e-06</td>\n",
       "      <td>2.599846e-07</td>\n",
       "      <td>4.327444e-08</td>\n",
       "      <td>1.617358e-06</td>\n",
       "      <td>2.311371e-08</td>\n",
       "      <td>1.009156e-06</td>\n",
       "      <td>6.765463e-08</td>\n",
       "      <td>9.082696e-08</td>\n",
       "      <td>1.509233e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995519</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.589938e-08</td>\n",
       "      <td>1.715680e-09</td>\n",
       "      <td>5.441116e-09</td>\n",
       "      <td>2.073083e-10</td>\n",
       "      <td>1.186772e-10</td>\n",
       "      <td>1.868365e-10</td>\n",
       "      <td>6.800536e-10</td>\n",
       "      <td>1.977087e-09</td>\n",
       "      <td>3.764251e-10</td>\n",
       "      <td>1.347726e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hear</td>\n",
       "      <td>O-v.perception</td>\n",
       "      <td>26</td>\n",
       "      <td>O-v.perception</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>...</td>\n",
       "      <td>7.995566e-09</td>\n",
       "      <td>7.173501e-08</td>\n",
       "      <td>6.073835e-06</td>\n",
       "      <td>4.889142e-08</td>\n",
       "      <td>1.474222e-07</td>\n",
       "      <td>1.158052e-08</td>\n",
       "      <td>1.779303e-07</td>\n",
       "      <td>3.386133e-07</td>\n",
       "      <td>1.222154e-07</td>\n",
       "      <td>7.930803e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>enough</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951448</td>\n",
       "      <td>0.021746</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>...</td>\n",
       "      <td>8.819788e-08</td>\n",
       "      <td>9.614047e-08</td>\n",
       "      <td>9.845042e-08</td>\n",
       "      <td>2.515755e-08</td>\n",
       "      <td>1.673350e-08</td>\n",
       "      <td>3.748133e-09</td>\n",
       "      <td>7.123056e-08</td>\n",
       "      <td>2.861959e-07</td>\n",
       "      <td>4.182288e-08</td>\n",
       "      <td>4.485106e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>talking</td>\n",
       "      <td>O-v.communication</td>\n",
       "      <td>7</td>\n",
       "      <td>O-v.communication</td>\n",
       "      <td>7</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.295478</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027149e-07</td>\n",
       "      <td>1.736899e-07</td>\n",
       "      <td>1.132739e-06</td>\n",
       "      <td>1.610143e-06</td>\n",
       "      <td>3.967633e-08</td>\n",
       "      <td>2.301025e-08</td>\n",
       "      <td>2.259521e-07</td>\n",
       "      <td>6.651941e-08</td>\n",
       "      <td>1.057945e-07</td>\n",
       "      <td>3.407447e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token Index       Tokens      Predicted Tag  Predicted Index  \\\n",
       "0            0  @JoJoLyrics  O-n.communication               17   \n",
       "1            1            I                  O                0   \n",
       "2            2         hear     O-v.perception               26   \n",
       "3            3       enough                  O                0   \n",
       "4            4      talking  O-v.communication                7   \n",
       "\n",
       "              Ground Ground Index         O         I  O-v.stative  O-n.group  \\\n",
       "0                  O            0  0.311954  0.188062     0.087458   0.021254   \n",
       "1                  O            0  0.995519  0.000021     0.000003   0.000003   \n",
       "2     O-v.perception           26  0.000691  0.007862     0.000761   0.000020   \n",
       "3                  O            0  0.951448  0.021746     0.000095   0.000033   \n",
       "4  O-v.communication            7  0.005734  0.295478     0.000332   0.000029   \n",
       "\n",
       "   ...          B-??     B-n.plant  o-v.communication   o-v.emotion  \\\n",
       "0  ...  2.375879e-08  3.950812e-06       2.599846e-07  4.327444e-08   \n",
       "1  ...  1.589938e-08  1.715680e-09       5.441116e-09  2.073083e-10   \n",
       "2  ...  7.995566e-09  7.173501e-08       6.073835e-06  4.889142e-08   \n",
       "3  ...  8.819788e-08  9.614047e-08       9.845042e-08  2.515755e-08   \n",
       "4  ...  1.027149e-07  1.736899e-07       1.132739e-06  1.610143e-06   \n",
       "\n",
       "   b-n.substance     B-n.other  b-v.possession  b-n.quantity  \\\n",
       "0   1.617358e-06  2.311371e-08    1.009156e-06  6.765463e-08   \n",
       "1   1.186772e-10  1.868365e-10    6.800536e-10  1.977087e-09   \n",
       "2   1.474222e-07  1.158052e-08    1.779303e-07  3.386133e-07   \n",
       "3   1.673350e-08  3.748133e-09    7.123056e-08  2.861959e-07   \n",
       "4   3.967633e-08  2.301025e-08    2.259521e-07  6.651941e-08   \n",
       "\n",
       "   o-n.naturalobject  b-n.location  \n",
       "0       9.082696e-08  1.509233e-08  \n",
       "1       3.764251e-10  1.347726e-10  \n",
       "2       1.222154e-07  7.930803e-09  \n",
       "3       4.182288e-08  4.485106e-09  \n",
       "4       1.057945e-07  3.407447e-08  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(dimsum_consolidated_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen",
   "language": "python",
   "name": "allen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
