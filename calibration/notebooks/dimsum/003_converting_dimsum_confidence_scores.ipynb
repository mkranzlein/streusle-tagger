{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DiMSUM Confidence Scores\n",
    "\n",
    "- Modified dimsum_to_jsonl.py to include label field by composing subtag fields into one string\n",
    "- Read dimsum using dataset_reader\n",
    "- Convert all.csv to all_newlabels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Michael\\dev\\streusle-tagger\n"
     ]
    }
   ],
   "source": [
    "# Notebook starts in notebooks folder. Change working directory back to streusle-tagger\n",
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Michael\\apps\\Anaconda3\\envs\\allen\\lib\\site-packages\\allennlp\\service\\predictors\\__init__.py:23: FutureWarning: allennlp.service.predictors.* has been depreciated. Please use allennlp.predictors.*\n",
      "  \"Please use allennlp.predictors.*\", FutureWarning)\n",
      "C:\\Michael\\apps\\Anaconda3\\envs\\allen\\lib\\site-packages\\allennlp\\service\\predictors\\predictor.py:6: FutureWarning: allennlp.service.predictors.* has been deprecated. Please use allennlp.predictors.*\n",
      "  \" Please use allennlp.predictors.*\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# System imports\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# Add parent of streusle-tagger to path (streusle should be in this folder)\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "# External imports\n",
    "import allennlp.nn.util as util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.util import import_submodules\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.training.util import datasets_from_params\n",
    "\n",
    "import_submodules(\"streusle_tagger\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_jsonnet not loaded, treating training_config/streusle_bert_large_cased/streusle_bert_large_cased_no_constraints.jsonnet as json\n",
      "Your BERT model appears to be cased, but your indexer is lowercasing tokens.\n",
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
      "2723it [00:00, 6091.72it/s]\n",
      "554it [00:00, 5539.68it/s]\n",
      "535it [00:00, 12435.66it/s]\n",
      "Your BERT model appears to be cased, but your indexer is lowercasing tokens.\n",
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n"
     ]
    }
   ],
   "source": [
    "params = Params.from_file(\"training_config/streusle_bert_large_cased/streusle_bert_large_cased_no_constraints.jsonnet\")\n",
    "datasets = datasets_from_params(deepcopy(params))\n",
    "dataset_reader_params = deepcopy(params).pop(\"dataset_reader\")\n",
    "dataset_reader = DatasetReader.from_params(dataset_reader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_csv(\"calibration/labels_dict.csv\")\n",
    "\n",
    "dimsum_test_path = \"data/dimsum16/dimsum16_test_updated_labeled_reformatted.json\"\n",
    "\n",
    "def read(file_path):\n",
    "    with open(file_path, 'r') as tagging_file:\n",
    "        tagging_data = json.load(tagging_file)\n",
    "        for i, x in enumerate(tagging_data):\n",
    "            if i % 200 == 0:\n",
    "                print(i)\n",
    "            tokens = [_ for _ in x[\"tokens\"]]\n",
    "            # Get their associated upos\n",
    "            upos_tags = [_ for _ in x[\"upos_tags\"]]\n",
    "\n",
    "            # Get their associated lemma\n",
    "            lemmas = [_ for _ in x[\"lemmas\"]]\n",
    "            \n",
    "            labels = [_ for _ in x[\"label\"]]\n",
    "            \n",
    "            yield dataset_reader.text_to_instance(tokens, upos_tags, lemmas, labels)\n",
    "            \n",
    "dimsum_test = list(read(dimsum_test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground = []\n",
    "for i in dimsum_test:\n",
    "    ground.extend(i.get(\"tags\").labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ground = []\n",
    "\n",
    "# If there's a noun or verb supersense label, the lexcat has to be NOUN or VERB (exceptions are usually due to MWEs)\n",
    "for g in ground:\n",
    "    if \"-n.\" in g and \"NOUN\" not in g:\n",
    "        x = g[:g.index(\"-\", 1) + 1] + \"NOUN\" + g[g.index(\"-\", 2):]\n",
    "    elif \"-v.\" in g and \"VERB\" not in g:\n",
    "        x = g[:g.index(\"-\", 1) + 1] + \"VERB\" + g[g.index(\"-\", 2):]\n",
    "    else:\n",
    "        x = g\n",
    "    corrected_ground.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"calibration/consolidated_labels.pickle\", \"rb\") as f:\n",
    "    new_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the CSVs for all sentences and save the merged version\n",
    "confidence_scores_path = \"calibration/confidence_scores/dimsum_test\"\n",
    "\n",
    "dfs = []\n",
    "for filename in os.listdir(confidence_scores_path):\n",
    "    if filename.startswith(\"0\") and filename.endswith(\".csv\"):\n",
    "        df = pd.read_csv(f\"{confidence_scores_path}/{filename}\")\n",
    "        dfs.append(df)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df.to_csv(f\"{confidence_scores_path}/all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Predicted Tags</th>\n",
       "      <th>Predicted Tag Indexes</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>590</th>\n",
       "      <th>591</th>\n",
       "      <th>592</th>\n",
       "      <th>593</th>\n",
       "      <th>594</th>\n",
       "      <th>595</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@JoJoLyrics</td>\n",
       "      <td>O-N-n.COMMUNICATION</td>\n",
       "      <td>27</td>\n",
       "      <td>3.308357e-03</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.187076</td>\n",
       "      <td>2.004502e-02</td>\n",
       "      <td>6.822077e-04</td>\n",
       "      <td>0.022586</td>\n",
       "      <td>...</td>\n",
       "      <td>8.651178e-08</td>\n",
       "      <td>1.191500e-08</td>\n",
       "      <td>1.492807e-07</td>\n",
       "      <td>9.625937e-08</td>\n",
       "      <td>1.617215e-07</td>\n",
       "      <td>2.149607e-08</td>\n",
       "      <td>1.509233e-08</td>\n",
       "      <td>3.212832e-07</td>\n",
       "      <td>1.995928e-07</td>\n",
       "      <td>2.425950e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>O-PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>3.710947e-07</td>\n",
       "      <td>0.995478</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>8.467397e-07</td>\n",
       "      <td>3.974892e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.063442e-10</td>\n",
       "      <td>1.543950e-10</td>\n",
       "      <td>1.109404e-10</td>\n",
       "      <td>1.433815e-10</td>\n",
       "      <td>6.351943e-11</td>\n",
       "      <td>1.549071e-10</td>\n",
       "      <td>1.347726e-10</td>\n",
       "      <td>7.412362e-11</td>\n",
       "      <td>1.141272e-10</td>\n",
       "      <td>4.027880e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hear</td>\n",
       "      <td>O-V-v.perception</td>\n",
       "      <td>45</td>\n",
       "      <td>1.834077e-06</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>3.886628e-04</td>\n",
       "      <td>7.104369e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>6.379876e-09</td>\n",
       "      <td>5.383308e-09</td>\n",
       "      <td>7.684921e-09</td>\n",
       "      <td>3.885210e-09</td>\n",
       "      <td>1.200826e-08</td>\n",
       "      <td>8.716266e-09</td>\n",
       "      <td>7.930803e-09</td>\n",
       "      <td>8.395023e-09</td>\n",
       "      <td>6.668426e-09</td>\n",
       "      <td>1.063727e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>enough</td>\n",
       "      <td>O-ADV</td>\n",
       "      <td>5</td>\n",
       "      <td>1.044289e-05</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>9.836438e-02</td>\n",
       "      <td>1.795487e-03</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>...</td>\n",
       "      <td>2.715171e-09</td>\n",
       "      <td>4.363862e-09</td>\n",
       "      <td>3.653439e-09</td>\n",
       "      <td>2.914954e-09</td>\n",
       "      <td>8.935501e-09</td>\n",
       "      <td>4.649278e-09</td>\n",
       "      <td>4.485106e-09</td>\n",
       "      <td>3.533208e-09</td>\n",
       "      <td>6.058807e-09</td>\n",
       "      <td>3.257677e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>talking</td>\n",
       "      <td>O-V-v.communication</td>\n",
       "      <td>13</td>\n",
       "      <td>3.740599e-05</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>1.134977e-03</td>\n",
       "      <td>9.664433e-06</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>...</td>\n",
       "      <td>2.200114e-08</td>\n",
       "      <td>4.902813e-08</td>\n",
       "      <td>2.117961e-08</td>\n",
       "      <td>2.007143e-08</td>\n",
       "      <td>3.957958e-08</td>\n",
       "      <td>3.524527e-08</td>\n",
       "      <td>3.407447e-08</td>\n",
       "      <td>3.588781e-08</td>\n",
       "      <td>3.603157e-08</td>\n",
       "      <td>5.895182e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Tokens       Predicted Tags  Predicted Tag Indexes  \\\n",
       "0           0  @JoJoLyrics  O-N-n.COMMUNICATION                     27   \n",
       "1           1            I               O-PRON                      1   \n",
       "2           2         hear     O-V-v.perception                     45   \n",
       "3           3       enough                O-ADV                      5   \n",
       "4           4      talking  O-V-v.communication                     13   \n",
       "\n",
       "              0         1         2             3             4         5  \\\n",
       "0  3.308357e-03  0.000672  0.187076  2.004502e-02  6.822077e-04  0.022586   \n",
       "1  3.710947e-07  0.995478  0.000021  8.467397e-07  3.974892e-07  0.000002   \n",
       "2  1.834077e-06  0.000019  0.007406  3.886628e-04  7.104369e-05  0.000004   \n",
       "3  1.044289e-05  0.000255  0.011356  9.836438e-02  1.795487e-03  0.849829   \n",
       "4  3.740599e-05  0.000319  0.013987  1.134977e-03  9.664433e-06  0.003871   \n",
       "\n",
       "   ...           586           587           588           589           590  \\\n",
       "0  ...  8.651178e-08  1.191500e-08  1.492807e-07  9.625937e-08  1.617215e-07   \n",
       "1  ...  1.063442e-10  1.543950e-10  1.109404e-10  1.433815e-10  6.351943e-11   \n",
       "2  ...  6.379876e-09  5.383308e-09  7.684921e-09  3.885210e-09  1.200826e-08   \n",
       "3  ...  2.715171e-09  4.363862e-09  3.653439e-09  2.914954e-09  8.935501e-09   \n",
       "4  ...  2.200114e-08  4.902813e-08  2.117961e-08  2.007143e-08  3.957958e-08   \n",
       "\n",
       "            591           592           593           594           595  \n",
       "0  2.149607e-08  1.509233e-08  3.212832e-07  1.995928e-07  2.425950e-07  \n",
       "1  1.549071e-10  1.347726e-10  7.412362e-11  1.141272e-10  4.027880e-11  \n",
       "2  8.716266e-09  7.930803e-09  8.395023e-09  6.668426e-09  1.063727e-08  \n",
       "3  4.649278e-09  4.485106e-09  3.533208e-09  6.058807e-09  3.257677e-09  \n",
       "4  3.524527e-08  3.407447e-08  3.588781e-08  3.603157e-08  5.895182e-08  \n",
       "\n",
       "[5 rows x 600 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimsum_df = pd.read_csv(f\"{confidence_scores_path}/all.csv\")\n",
    "dimsum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently running confidence scores, so only use corrected ground up to what has been calculated so far.\n",
    "dimsum_df[\"Ground\"] = corrected_ground[0:len(dimsum_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_columns = [\"Token Index\", \"Tokens\", \"Predicted Tag\", \"Predicted Index\", \"Ground\", \"Ground Index\"] + list(new_labels.keys())\n",
    "new_df_columns\n",
    "new_df = pd.DataFrame(columns=new_df_columns)\n",
    "\n",
    "new_df[\"Token Index\"] = dimsum_df[\"Unnamed: 0\"]\n",
    "new_df[\"Tokens\"] = dimsum_df[\"Tokens\"]\n",
    "\n",
    "old_index_to_new_label = {}\n",
    "for k, v in new_labels.items():\n",
    "    for num in v:\n",
    "        old_index_to_new_label[num] = k\n",
    "\n",
    "new_labels_list = list(new_labels)\n",
    "new_label_to_new_index = dict(zip(new_labels_list, list(range(len(new_labels_list)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels and indexes using consolidated labelset\n",
    "predicted_labels = []\n",
    "predicted_label_indexes = []\n",
    "for index in dimsum_df[\"Predicted Tag Indexes\"]:\n",
    "    new_label = old_index_to_new_label[index]\n",
    "    predicted_labels.append(new_label)\n",
    "    new_index = new_label_to_new_index[new_label]\n",
    "    predicted_label_indexes.append(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986 \t o-NOUN-n.state\n",
      "2039 \t B-NOUN\n",
      "2588 \t b-NOUN-n.act\n",
      "2852 \t O-VERB-v.weather\n",
      "3458 \t O-NOUN\n",
      "4288 \t o-INTJ\n",
      "4580 \t B-NOUN\n",
      "6232 \t O-NOUN\n",
      "8391 \t O-NOUN\n",
      "10825 \t O-VERB-v.weather\n",
      "11879 \t B-NOUN-n.motive\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\"CCONJ\": \"CONJ\",\n",
    "              \"DISC\": \"X\",\n",
    "              \"INF\": \"PART\",\n",
    "              \"INF.P\" : \"PART\",\n",
    "              \"N\": \"NOUN\",\n",
    "              \"P\": \"ADP\",\n",
    "              \"POSS\": \"PART\",\n",
    "              \"PP\": \"ADP\",\n",
    "              \"PRON.POSS\": \"PRON\",\n",
    "              \"V\":\n",
    "              \"VERB\",\n",
    "              \"V.IAV\":\"VERB\",\n",
    "              \"V.LVC.cause\": \"VERB\",\n",
    "              \"V.LVC.full\": \"VERB\",\n",
    "              \"V.VID\": \"VERB\",\n",
    "              \"V.VPC.full\": \"VERB\",\n",
    "              \"V.VPC.semi\": \"VERB\",\n",
    "              \"_\": \"X\"}\n",
    "\n",
    "\n",
    "ground_indexes = []\n",
    "for i, label in enumerate(dimsum_df[\"Ground\"]):\n",
    "    \n",
    "    label = label.replace(\"natural_object\", \"naturalobject\")\n",
    "    label = label.replace(\"PROPN\", \"NOUN\")\n",
    "    \n",
    "    # For dealing with manually annotated cases where \"lexcat=\" note is provided\n",
    "    if \"lexcat=\" in label:\n",
    "        new_lexcat = label[label.index(\"=\") + 1:]\n",
    "        mapped_new_lexcat = labels_map[new_lexcat] if new_lexcat in labels_map else new_lexcat\n",
    "        new_label = label[:label.index(\"-\") + 1] + mapped_new_lexcat\n",
    "        ground_indexes.append(new_label_to_new_index[new_label])\n",
    "        continue\n",
    "    try:\n",
    "        if label.startswith(\"I\"):\n",
    "            ground_indexes.append(new_label_to_new_index[\"I-X\"])\n",
    "        elif label.startswith(\"i\"):\n",
    "            ground_indexes.append(new_label_to_new_index[\"i-X\"])\n",
    "        else:\n",
    "            ground_indexes.append(new_label_to_new_index[label])\n",
    "    except:\n",
    "        print(i, \"\\t\", label)\n",
    "        ground_indexes.append(\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"Predicted Tag\"] = predicted_labels\n",
    "new_df[\"Predicted Index\"] = predicted_label_indexes\n",
    "new_df[\"Ground\"] = dimsum_df[\"Ground\"]\n",
    "new_df[\"Ground Index\"] = ground_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token Index</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Predicted Tag</th>\n",
       "      <th>Predicted Index</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Ground Index</th>\n",
       "      <th>O-PUNCT</th>\n",
       "      <th>O-PRON</th>\n",
       "      <th>I-X</th>\n",
       "      <th>O-ADJ</th>\n",
       "      <th>...</th>\n",
       "      <th>o-VERB-v.communication</th>\n",
       "      <th>o-VERB-v.emotion</th>\n",
       "      <th>b-NOUN-n.substance</th>\n",
       "      <th>B-NOUN-n.other</th>\n",
       "      <th>b-VERB-v.possession</th>\n",
       "      <th>b-NOUN-n.quantity</th>\n",
       "      <th>o-NOUN-n.naturalobject</th>\n",
       "      <th>B-PART</th>\n",
       "      <th>B-NUM</th>\n",
       "      <th>b-NOUN-n.location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@JoJoLyrics</td>\n",
       "      <td>O-NOUN-n.communication</td>\n",
       "      <td>27</td>\n",
       "      <td>O-X</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>O-PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>O-PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hear</td>\n",
       "      <td>O-VERB-v.perception</td>\n",
       "      <td>39</td>\n",
       "      <td>O-VERB-v.perception</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>enough</td>\n",
       "      <td>O-ADV</td>\n",
       "      <td>5</td>\n",
       "      <td>O-ADV</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>talking</td>\n",
       "      <td>O-VERB-v.communication</td>\n",
       "      <td>13</td>\n",
       "      <td>O-VERB-v.communication</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token Index       Tokens           Predicted Tag  Predicted Index  \\\n",
       "0            0  @JoJoLyrics  O-NOUN-n.communication               27   \n",
       "1            1            I                  O-PRON                1   \n",
       "2            2         hear     O-VERB-v.perception               39   \n",
       "3            3       enough                   O-ADV                5   \n",
       "4            4      talking  O-VERB-v.communication               13   \n",
       "\n",
       "                   Ground Ground Index O-PUNCT O-PRON  I-X O-ADJ  ...  \\\n",
       "0                     O-X           60     NaN    NaN  NaN   NaN  ...   \n",
       "1                  O-PRON            1     NaN    NaN  NaN   NaN  ...   \n",
       "2     O-VERB-v.perception           39     NaN    NaN  NaN   NaN  ...   \n",
       "3                   O-ADV            5     NaN    NaN  NaN   NaN  ...   \n",
       "4  O-VERB-v.communication           13     NaN    NaN  NaN   NaN  ...   \n",
       "\n",
       "  o-VERB-v.communication o-VERB-v.emotion b-NOUN-n.substance B-NOUN-n.other  \\\n",
       "0                    NaN              NaN                NaN            NaN   \n",
       "1                    NaN              NaN                NaN            NaN   \n",
       "2                    NaN              NaN                NaN            NaN   \n",
       "3                    NaN              NaN                NaN            NaN   \n",
       "4                    NaN              NaN                NaN            NaN   \n",
       "\n",
       "  b-VERB-v.possession b-NOUN-n.quantity o-NOUN-n.naturalobject B-PART B-NUM  \\\n",
       "0                 NaN               NaN                    NaN    NaN   NaN   \n",
       "1                 NaN               NaN                    NaN    NaN   NaN   \n",
       "2                 NaN               NaN                    NaN    NaN   NaN   \n",
       "3                 NaN               NaN                    NaN    NaN   NaN   \n",
       "4                 NaN               NaN                    NaN    NaN   NaN   \n",
       "\n",
       "  b-NOUN-n.location  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_scores(new_label, row_index):\n",
    "    score_sum = 0\n",
    "    \n",
    "    for i in new_labels[new_label]:\n",
    "        score_sum += dimsum_df[str(i)][row_index]\n",
    "        \n",
    "    return score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_column_names = list(new_df.columns)[6:]\n",
    "\n",
    "score_columns = {}\n",
    "for c in score_column_names:\n",
    "    score_columns[c] = []\n",
    "for i, row in new_df.iterrows():\n",
    "    for c in score_column_names:\n",
    "        score_columns[c].append(sum_scores(c, i))\n",
    "\n",
    "for c in score_column_names:\n",
    "    new_df[c] = score_columns[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token Index</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Predicted Tag</th>\n",
       "      <th>Predicted Index</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Ground Index</th>\n",
       "      <th>O-PUNCT</th>\n",
       "      <th>O-PRON</th>\n",
       "      <th>I-X</th>\n",
       "      <th>O-ADJ</th>\n",
       "      <th>...</th>\n",
       "      <th>o-VERB-v.communication</th>\n",
       "      <th>o-VERB-v.emotion</th>\n",
       "      <th>b-NOUN-n.substance</th>\n",
       "      <th>B-NOUN-n.other</th>\n",
       "      <th>b-VERB-v.possession</th>\n",
       "      <th>b-NOUN-n.quantity</th>\n",
       "      <th>o-NOUN-n.naturalobject</th>\n",
       "      <th>B-PART</th>\n",
       "      <th>B-NUM</th>\n",
       "      <th>b-NOUN-n.location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@JoJoLyrics</td>\n",
       "      <td>O-NOUN-n.communication</td>\n",
       "      <td>27</td>\n",
       "      <td>O-X</td>\n",
       "      <td>60</td>\n",
       "      <td>3.308357e-03</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.188062</td>\n",
       "      <td>2.004502e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.599846e-07</td>\n",
       "      <td>4.327444e-08</td>\n",
       "      <td>1.617358e-06</td>\n",
       "      <td>2.311371e-08</td>\n",
       "      <td>1.009156e-06</td>\n",
       "      <td>6.765463e-08</td>\n",
       "      <td>9.082696e-08</td>\n",
       "      <td>4.148700e-06</td>\n",
       "      <td>6.925350e-07</td>\n",
       "      <td>1.509233e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>O-PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>O-PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>3.710947e-07</td>\n",
       "      <td>0.995479</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>8.467397e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441116e-09</td>\n",
       "      <td>2.073083e-10</td>\n",
       "      <td>1.186772e-10</td>\n",
       "      <td>1.868365e-10</td>\n",
       "      <td>6.800536e-10</td>\n",
       "      <td>1.977087e-09</td>\n",
       "      <td>3.764251e-10</td>\n",
       "      <td>1.256866e-09</td>\n",
       "      <td>1.074616e-10</td>\n",
       "      <td>1.347726e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hear</td>\n",
       "      <td>O-VERB-v.perception</td>\n",
       "      <td>39</td>\n",
       "      <td>O-VERB-v.perception</td>\n",
       "      <td>39</td>\n",
       "      <td>1.834077e-06</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>3.886628e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>6.073835e-06</td>\n",
       "      <td>4.889142e-08</td>\n",
       "      <td>1.474222e-07</td>\n",
       "      <td>1.158052e-08</td>\n",
       "      <td>1.779303e-07</td>\n",
       "      <td>3.386133e-07</td>\n",
       "      <td>1.222154e-07</td>\n",
       "      <td>5.934713e-08</td>\n",
       "      <td>9.012044e-09</td>\n",
       "      <td>7.930803e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>enough</td>\n",
       "      <td>O-ADV</td>\n",
       "      <td>5</td>\n",
       "      <td>O-ADV</td>\n",
       "      <td>5</td>\n",
       "      <td>1.044289e-05</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.021746</td>\n",
       "      <td>9.836438e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>9.845042e-08</td>\n",
       "      <td>2.515755e-08</td>\n",
       "      <td>1.673350e-08</td>\n",
       "      <td>3.748133e-09</td>\n",
       "      <td>7.123056e-08</td>\n",
       "      <td>2.861959e-07</td>\n",
       "      <td>4.182288e-08</td>\n",
       "      <td>1.734542e-07</td>\n",
       "      <td>1.159856e-08</td>\n",
       "      <td>4.485106e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>talking</td>\n",
       "      <td>O-VERB-v.communication</td>\n",
       "      <td>13</td>\n",
       "      <td>O-VERB-v.communication</td>\n",
       "      <td>13</td>\n",
       "      <td>3.740599e-05</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.295478</td>\n",
       "      <td>1.134977e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.132739e-06</td>\n",
       "      <td>1.610143e-06</td>\n",
       "      <td>3.967633e-08</td>\n",
       "      <td>2.301025e-08</td>\n",
       "      <td>2.259521e-07</td>\n",
       "      <td>6.651941e-08</td>\n",
       "      <td>1.057945e-07</td>\n",
       "      <td>1.251099e-07</td>\n",
       "      <td>3.793691e-08</td>\n",
       "      <td>3.407447e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token Index       Tokens           Predicted Tag  Predicted Index  \\\n",
       "0            0  @JoJoLyrics  O-NOUN-n.communication               27   \n",
       "1            1            I                  O-PRON                1   \n",
       "2            2         hear     O-VERB-v.perception               39   \n",
       "3            3       enough                   O-ADV                5   \n",
       "4            4      talking  O-VERB-v.communication               13   \n",
       "\n",
       "                   Ground Ground Index       O-PUNCT    O-PRON       I-X  \\\n",
       "0                     O-X           60  3.308357e-03  0.002244  0.188062   \n",
       "1                  O-PRON            1  3.710947e-07  0.995479  0.000021   \n",
       "2     O-VERB-v.perception           39  1.834077e-06  0.000035  0.007862   \n",
       "3                   O-ADV            5  1.044289e-05  0.000296  0.021746   \n",
       "4  O-VERB-v.communication           13  3.740599e-05  0.000382  0.295478   \n",
       "\n",
       "          O-ADJ  ...  o-VERB-v.communication  o-VERB-v.emotion  \\\n",
       "0  2.004502e-02  ...            2.599846e-07      4.327444e-08   \n",
       "1  8.467397e-07  ...            5.441116e-09      2.073083e-10   \n",
       "2  3.886628e-04  ...            6.073835e-06      4.889142e-08   \n",
       "3  9.836438e-02  ...            9.845042e-08      2.515755e-08   \n",
       "4  1.134977e-03  ...            1.132739e-06      1.610143e-06   \n",
       "\n",
       "   b-NOUN-n.substance  B-NOUN-n.other  b-VERB-v.possession  b-NOUN-n.quantity  \\\n",
       "0        1.617358e-06    2.311371e-08         1.009156e-06       6.765463e-08   \n",
       "1        1.186772e-10    1.868365e-10         6.800536e-10       1.977087e-09   \n",
       "2        1.474222e-07    1.158052e-08         1.779303e-07       3.386133e-07   \n",
       "3        1.673350e-08    3.748133e-09         7.123056e-08       2.861959e-07   \n",
       "4        3.967633e-08    2.301025e-08         2.259521e-07       6.651941e-08   \n",
       "\n",
       "   o-NOUN-n.naturalobject        B-PART         B-NUM  b-NOUN-n.location  \n",
       "0            9.082696e-08  4.148700e-06  6.925350e-07       1.509233e-08  \n",
       "1            3.764251e-10  1.256866e-09  1.074616e-10       1.347726e-10  \n",
       "2            1.222154e-07  5.934713e-08  9.012044e-09       7.930803e-09  \n",
       "3            4.182288e-08  1.734542e-07  1.159856e-08       4.485106e-09  \n",
       "4            1.057945e-07  1.251099e-07  3.793691e-08       3.407447e-08  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"calibration/confidence_scores/dimsum_test/all_consolidated.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen",
   "language": "python",
   "name": "allen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
