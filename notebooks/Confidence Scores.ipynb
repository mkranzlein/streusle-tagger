{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Confidence Scores on Dev and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# External imports\n",
    "import allennlp.nn.util as util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from allennlp.commands.train import train_model\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.util import import_submodules\n",
    "from allennlp.data.dataset import Batch\n",
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.nn.util import logsumexp\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.training.optimizers import Optimizer\n",
    "from allennlp.training.util import datasets_from_params\n",
    "\n",
    "import_submodules(\"streusle_tagger\")\n",
    "\n",
    "from streusle_tagger.dataset_readers import StreusleDatasetReader\n",
    "\n",
    "params = Params.from_file(\"../training_config/streusle_bert_large/streusle_bert_large_cased_no_constraints.jsonnet\")\n",
    "archive = load_archive(\"../saved_models/no_constraints/model.tar.gz\")\n",
    "model = archive.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label = model.vocab.get_index_to_token_vocabulary(model._label_namespace)\n",
    "label_to_index = dict(zip(index_to_label.values(), index_to_label.keys()))\n",
    "\n",
    "labels_df = pd.DataFrame(label_to_index, columns=[\"Label\", \"Index\"])\n",
    "labels_df.to_csv(\"confidence_results/\")\n",
    "reader = StreusleDatasetReader()\n",
    "datasets = datasets_from_params(deepcopy(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denominator(crf, logits):\n",
    "    if len(logits.size()) > 1:\n",
    "        sequence_length, num_tags = logits.size()\n",
    "        alpha = crf.start_transitions + logits[0]\n",
    "    else:\n",
    "        sequence_length = 1\n",
    "        num_tags = logits.size()[0]\n",
    "        alpha = crf.start_transitions + logits\n",
    "        \n",
    "    forward_trellis = []\n",
    "    forward_trellis.append(alpha)\n",
    "    \n",
    "    for i in range(1, sequence_length):\n",
    "        forward_trellis.append(forward_trellis[i - 1] + logsumexp(logits[i].view(1, num_tags) + crf.transitions))\n",
    "\n",
    "    stops =  forward_trellis[sequence_length - 1] + crf.end_transitions\n",
    "    forward_trellis.append(stops)\n",
    "    \n",
    "    backward_trellis = []\n",
    "\n",
    "    if sequence_length > 1:\n",
    "        backward_trellis.append(logsumexp(logits[sequence_length - 1].view(1, num_tags) + crf.transitions))\n",
    "\n",
    "    reverse_indexes = list(range(1, sequence_length - 1))\n",
    "    reverse_indexes.reverse()\n",
    "    for i in reverse_indexes:\n",
    "        backward_trellis.append(backward_trellis[sequence_length - i - 2] + logsumexp(logits[i].view(1, num_tags) + crf.transitions))\n",
    "        \n",
    "    # This never gets used; it's just for more intuitive indexing in numerator calculation\n",
    "    backward_trellis.append([\"dummy placeholder\"])\n",
    "    backward_trellis.reverse()\n",
    "    return forward_trellis, backward_trellis, util.logsumexp(stops)\n",
    "\n",
    "def numerator(crf, logits, forward_trellis, backward_trellis, tag_num, word_num):\n",
    "    if len(logits.size()) > 1:\n",
    "        sequence_length, num_tags = logits.size()\n",
    "    else:\n",
    "        sequence_length = 1\n",
    "        num_tags = logits.size()[0]\n",
    "    \n",
    "    if sequence_length == 1:\n",
    "        start_transition_mask = torch.zeros_like(crf.start_transitions)\n",
    "        start_transition_mask[tag_num] = 1\n",
    "        alpha = util.replace_masked_values(crf.start_transitions + logits, start_transition_mask, -1e32)\n",
    "        return logsumexp(alpha + crf.end_transitions)\n",
    "    \n",
    "    elif word_num == 0:\n",
    "        start_transition_mask = torch.zeros_like(crf.start_transitions)\n",
    "        start_transition_mask[tag_num] = 1\n",
    "        alpha = util.replace_masked_values(crf.start_transitions + logits[0], start_transition_mask, -1e32)\n",
    "        beta = backward_trellis[1]\n",
    "        return logsumexp(alpha + beta + crf.end_transitions)\n",
    "    \n",
    "    else:\n",
    "        alpha = forward_trellis[word_num - 1]\n",
    "        \n",
    "        emit_mask = torch.zeros_like(logits[word_num])\n",
    "        emit_mask[tag_num] = 1\n",
    "        emit_scores = util.replace_masked_values(logits[word_num], emit_mask, -1e32)\n",
    "        \n",
    "        transition_scores = crf.transitions\n",
    "        transition_mask = torch.zeros_like(transition_scores)\n",
    "        transition_mask[:, tag_num] = 1\n",
    "        transition_scores = util.replace_masked_values(transition_scores, transition_mask, -1e32)\n",
    "        \n",
    "        inner = alpha.view(num_tags, 1) + emit_scores.view(1, num_tags) + transition_scores\n",
    "        alpha = logsumexp(inner, 0)\n",
    "        if word_num == sequence_length - 1:\n",
    "            return logsumexp(forward_trellis[word_num - 1] + logsumexp(emit_scores.view(1, num_tags) + transition_scores) + crf.end_transitions)\n",
    "        else:\n",
    "            beta = backward_trellis[word_num + 1]\n",
    "            return logsumexp(forward_trellis[word_num - 1] + logsumexp(emit_scores.view(1, num_tags) + transition_scores) + beta + crf.end_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_confidence(crf, sequence_logits):\n",
    "    \"\"\"Calculates matrix of confidence scores with num_words rows and num_tags columns.\"\"\"\n",
    "    confidence_matrix = []\n",
    "    num_tags = crf.num_tags\n",
    "    if len(sequence_logits.size()) == 1:\n",
    "        num_words = 1\n",
    "    else:\n",
    "        num_words = sequence_logits.size()[0]\n",
    "    \n",
    "    forward_trellis, backward_trellis, denom = denominator(model.crf, sequence_logits)\n",
    "    for i in range(num_words):\n",
    "        new_row = []\n",
    "        for j in range(num_tags):\n",
    "            numer = numerator(crf, sequence_logits, forward_trellis, backward_trellis, j, i)\n",
    "            confidence_score = math.exp(numer - denom)\n",
    "            new_row.append(confidence_score)\n",
    "        confidence_matrix.append(new_row)\n",
    "        \n",
    "    return confidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_confidence(dataset, dataset_name):\n",
    "    \"\"\"Creates one CSV file per sentence, containing metadata and confidence scores for all tag-token pairs.\"\"\"\n",
    "    \n",
    "    save_path = f\"../confidence_results/{dataset_name}\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    for i, instance in enumerate(dataset):\n",
    "        instance_batch = Batch([instance])\n",
    "        instance_batch.index_instances(model.vocab)\n",
    "\n",
    "        # Confidence scores\n",
    "        print(f\"Calculating confidence scores for instance {i}...\")\n",
    "        tokens = instance_batch.as_tensor_dict()[\"tokens\"]\n",
    "        embedded_tokens = model.text_field_embedder(tokens)\n",
    "        logits = model.tag_projection_layer(embedded_tokens).squeeze()\n",
    "        confidence_matrix = sentence_confidence(model.crf, logits)\n",
    "\n",
    "        # Metadata\n",
    "        tokens_list = np.array([[str(t) for t in instance.get(\"tokens\").tokens]]).transpose()\n",
    "        ground_truth_tags = instance.get(\"tags\").labels\n",
    "        ground_truth_tags_indexes = np.array([[label_to_index[tag] for tag in ground_truth_tags]]).transpose()\n",
    "        ground_truth_tags = np.array([ground_truth_tags]).transpose()\n",
    "        predicted_tags_indexes = (model.forward(**instance_batch.as_tensor_dict())[\"tags\"])[0]\n",
    "        predicted_tags = np.array([[index_to_label[i] for i in predicted_tags_indexes]]).transpose()\n",
    "        predicted_tags_indexes = np.array([predicted_tags_indexes]).transpose()\n",
    "        metadata = np.concatenate((tokens_list, ground_truth_tags, ground_truth_tags_indexes, predicted_tags, predicted_tags_indexes), axis=1)\n",
    "\n",
    "        # Combine metadata and confidence scores\n",
    "        data = np.concatenate((metadata, confidence_matrix), axis=1)\n",
    "        \n",
    "        # Write to file\n",
    "        columns = [\"Tokens\", \"Ground Truth\", \"Ground Truth Indexes\", \"Predicted Tags\", \"Predicted Tag Indexes\"] + [i for i in range(model.crf.num_tags)]\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        df.to_csv(f\"{save_path}/{i}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_confidence(datasets[\"validation\"], \"validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen",
   "language": "python",
   "name": "allen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
